{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fb5cf0c2-1fd3-4079-825e-013dd0067d43",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d3691e57-d884-407b-b95a-5d87d2dd8a6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a29a4610-9840-40ba-804e-4549b9fd1f36",
   "metadata": {},
   "source": [
    "**Local:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "72f677fb-6813-4755-a897-704958068b77",
   "metadata": {},
   "outputs": [],
   "source": [
    "import constants\n",
    "import constraints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "517ec99c-5e0c-4851-ab67-1b5dcd789e35",
   "metadata": {},
   "outputs": [],
   "source": [
    "constants.pandas_settings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e528ef3f-4752-4d5c-992d-fde18b2c535b",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Invalid file path or buffer object type: <class 'dict'>",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[0;32mIn [9]\u001b[0m, in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m dg_url\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhttps://feeds.datagolf.com/field-updates?tour=pga&file_format=json&key=6a626b6c312c0d33cfe157d614b5\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m      2\u001b[0m res \u001b[38;5;241m=\u001b[39m requests\u001b[38;5;241m.\u001b[39mget(dg_url) \n\u001b[0;32m----> 3\u001b[0m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_json\u001b[49m\u001b[43m(\u001b[49m\u001b[43mres\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjson\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/lib/python3.10/site-packages/pandas/util/_decorators.py:207\u001b[0m, in \u001b[0;36mdeprecate_kwarg.<locals>._deprecate_kwarg.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    205\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    206\u001b[0m         kwargs[new_arg_name] \u001b[38;5;241m=\u001b[39m new_arg_value\n\u001b[0;32m--> 207\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/lib/python3.10/site-packages/pandas/util/_decorators.py:311\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    305\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[1;32m    306\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    307\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39marguments),\n\u001b[1;32m    308\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[1;32m    309\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mstacklevel,\n\u001b[1;32m    310\u001b[0m     )\n\u001b[0;32m--> 311\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/lib/python3.10/site-packages/pandas/io/json/_json.py:588\u001b[0m, in \u001b[0;36mread_json\u001b[0;34m(path_or_buf, orient, typ, dtype, convert_axes, convert_dates, keep_default_dates, numpy, precise_float, date_unit, encoding, encoding_errors, lines, chunksize, compression, nrows, storage_options)\u001b[0m\n\u001b[1;32m    585\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m convert_axes \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m orient \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtable\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    586\u001b[0m     convert_axes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m--> 588\u001b[0m json_reader \u001b[38;5;241m=\u001b[39m \u001b[43mJsonReader\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    589\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpath_or_buf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    590\u001b[0m \u001b[43m    \u001b[49m\u001b[43morient\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43morient\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    591\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtyp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtyp\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    592\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    593\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconvert_axes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconvert_axes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    594\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconvert_dates\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconvert_dates\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    595\u001b[0m \u001b[43m    \u001b[49m\u001b[43mkeep_default_dates\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkeep_default_dates\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    596\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnumpy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnumpy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    597\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprecise_float\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprecise_float\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    598\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdate_unit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdate_unit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    599\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    600\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlines\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlines\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    601\u001b[0m \u001b[43m    \u001b[49m\u001b[43mchunksize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunksize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    602\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcompression\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    603\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnrows\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnrows\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    604\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    605\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding_errors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoding_errors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    606\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    608\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize:\n\u001b[1;32m    609\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m json_reader\n",
      "File \u001b[0;32m/usr/lib/python3.10/site-packages/pandas/io/json/_json.py:673\u001b[0m, in \u001b[0;36mJsonReader.__init__\u001b[0;34m(self, filepath_or_buffer, orient, typ, dtype, convert_axes, convert_dates, keep_default_dates, numpy, precise_float, date_unit, encoding, lines, chunksize, compression, nrows, storage_options, encoding_errors)\u001b[0m\n\u001b[1;32m    670\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlines:\n\u001b[1;32m    671\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnrows can only be passed if lines=True\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 673\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_data_from_filepath\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    674\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_preprocess_data(data)\n",
      "File \u001b[0;32m/usr/lib/python3.10/site-packages/pandas/io/json/_json.py:710\u001b[0m, in \u001b[0;36mJsonReader._get_data_from_filepath\u001b[0;34m(self, filepath_or_buffer)\u001b[0m\n\u001b[1;32m    703\u001b[0m filepath_or_buffer \u001b[38;5;241m=\u001b[39m stringify_path(filepath_or_buffer)\n\u001b[1;32m    704\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    705\u001b[0m     \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(filepath_or_buffer, \u001b[38;5;28mstr\u001b[39m)\n\u001b[1;32m    706\u001b[0m     \u001b[38;5;129;01mor\u001b[39;00m is_url(filepath_or_buffer)\n\u001b[1;32m    707\u001b[0m     \u001b[38;5;129;01mor\u001b[39;00m is_fsspec_url(filepath_or_buffer)\n\u001b[1;32m    708\u001b[0m     \u001b[38;5;129;01mor\u001b[39;00m file_exists(filepath_or_buffer)\n\u001b[1;32m    709\u001b[0m ):\n\u001b[0;32m--> 710\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    711\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    712\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    713\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    714\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompression\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    715\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    716\u001b[0m \u001b[43m        \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding_errors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    717\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    718\u001b[0m     filepath_or_buffer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n\u001b[1;32m    720\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m filepath_or_buffer\n",
      "File \u001b[0;32m/usr/lib/python3.10/site-packages/pandas/io/common.py:667\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    664\u001b[0m     codecs\u001b[38;5;241m.\u001b[39mlookup_error(errors)\n\u001b[1;32m    666\u001b[0m \u001b[38;5;66;03m# open URLs\u001b[39;00m\n\u001b[0;32m--> 667\u001b[0m ioargs \u001b[38;5;241m=\u001b[39m \u001b[43m_get_filepath_or_buffer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    668\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpath_or_buf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    669\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    670\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcompression\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    671\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    672\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    673\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    675\u001b[0m handle \u001b[38;5;241m=\u001b[39m ioargs\u001b[38;5;241m.\u001b[39mfilepath_or_buffer\n\u001b[1;32m    676\u001b[0m handles: \u001b[38;5;28mlist\u001b[39m[BaseBuffer]\n",
      "File \u001b[0;32m/usr/lib/python3.10/site-packages/pandas/io/common.py:424\u001b[0m, in \u001b[0;36m_get_filepath_or_buffer\u001b[0;34m(filepath_or_buffer, encoding, compression, mode, storage_options)\u001b[0m\n\u001b[1;32m    420\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\n\u001b[1;32m    421\u001b[0m     \u001b[38;5;28mhasattr\u001b[39m(filepath_or_buffer, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mread\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(filepath_or_buffer, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwrite\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    422\u001b[0m ):\n\u001b[1;32m    423\u001b[0m     msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid file path or buffer object type: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(filepath_or_buffer)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 424\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg)\n\u001b[1;32m    426\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m IOArgs(\n\u001b[1;32m    427\u001b[0m     filepath_or_buffer\u001b[38;5;241m=\u001b[39mfilepath_or_buffer,\n\u001b[1;32m    428\u001b[0m     encoding\u001b[38;5;241m=\u001b[39mencoding,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    431\u001b[0m     mode\u001b[38;5;241m=\u001b[39mmode,\n\u001b[1;32m    432\u001b[0m )\n",
      "\u001b[0;31mValueError\u001b[0m: Invalid file path or buffer object type: <class 'dict'>"
     ]
    }
   ],
   "source": [
    "dg_url='https://feeds.datagolf.com/field-updates?tour=pga&file_format=json&key=6a626b6c312c0d33cfe157d614b5'\n",
    "res = requests.get(dg_url) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "86bc5c91-4717-4eb7-9758-b8239bcfdf19",
   "metadata": {},
   "outputs": [],
   "source": [
    "def edit_fanduel():\n",
    "    df = pd.read_csv(f'../data/contest-files/{constants.tournament}.csv', usecols=constants.keep_cols)\n",
    "    df.columns = df.columns.str.lower()\n",
    "\n",
    "    ret = (df\n",
    "           .rename({'nickname': 'name'}, axis=1)\n",
    "           #.loc[(df['injury indicator']!='O') & (df['salary']>7000)]\n",
    "           .drop('injury indicator', axis=1)\n",
    "           .dropna()\n",
    "           .reset_index(drop=True)\n",
    "          )\n",
    "    \n",
    "    col_types = { 'name': 'str', 'fppg': 'float' }\n",
    "    \n",
    "    for col in ret.columns:\n",
    "        ret[col] = ret[col].astype(col_types.get(col,'int'))\n",
    "    \n",
    "    ret.to_pickle('../data/pickle-buffer/fanduel-data.pkl')\n",
    "    \n",
    "    return None\n",
    "\n",
    "\n",
    "def load_fanduel():\n",
    "    \n",
    "    edit_fanduel()\n",
    "    \n",
    "    return pd.read_pickle('../data/pickle-buffer/fanduel-data.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b1760918-d381-4d66-bcbb-d794d5c1945c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             nickname  fppg  played  salary injury indicator\n",
      "0        Rory McIlroy 78.01   13.00   12000              NaN\n",
      "1   Scottie Scheffler 80.40   20.00   11900              NaN\n",
      "2            Jon Rahm 73.35   14.00   11800              NaN\n",
      "3       Justin Thomas 84.55   17.00   11700              NaN\n",
      "4         Shane Lowry 61.60   12.00   11500              NaN\n",
      "5     Collin Morikawa 68.14   14.00   11400              NaN\n",
      "6   Xander Schauffele 77.94   16.00   11300              NaN\n",
      "7    Matt Fitzpatrick 63.88   16.00   11200              NaN\n",
      "8       Jordan Spieth 64.42   18.00   11100              NaN\n",
      "9      Will Zalatoris 62.94   17.00   11000              NaN\n",
      "10      Cameron Smith 72.89   14.00   10900              NaN\n",
      "11     Dustin Johnson 60.67   10.00   10800              NaN\n",
      "12    Patrick Cantlay 76.78   13.00   10700              NaN\n",
      "13     Viktor Hovland 71.50   16.00   10600              NaN\n",
      "14   Hideki Matsuyama 72.27   17.00   10500              NaN\n"
     ]
    }
   ],
   "source": [
    "edit_fanduel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b7bb2ef2-7946-4f4e-8299-deb1eb487bca",
   "metadata": {},
   "outputs": [],
   "source": [
    "strokes_gained_components = {\n",
    "    'tee': {\n",
    "        'url_id': 2567,\n",
    "        #'url': 'https://www.pgatour.com/stats/stat.02567.html',\n",
    "        'shortened': 'ott'\n",
    "    },\n",
    "    'approach': {\n",
    "        'url_id': 2568,\n",
    "        #'url': 'https://www.pgatour.com/stats/stat.02568.html',\n",
    "        'shortened': 'app'\n",
    "    },\n",
    "    'around': {\n",
    "        'url_id': 2569,\n",
    "        #'url': 'https://www.pgatour.com/stats/stat.02569.html',\n",
    "        'shortened': 'arg'\n",
    "    },\n",
    "    'green': {\n",
    "        'url_id': 2564,\n",
    "        #'url': 'https://www.pgatour.com/stats/stat.02564.html',\n",
    "        'shortened': 'putt'\n",
    "    },\n",
    "    'tee-to-green': {\n",
    "        'url_id': 2674,\n",
    "        #'url': 'https://www.pgatour.com/stats/stat.02674.html',\n",
    "        'shortened' : 'ttg'\n",
    "        }\n",
    "}\n",
    "\n",
    "new_col_names = {\n",
    "    'player name': 'name',\n",
    "    'rank this week': ' cur-rank',\n",
    "    'rank last week': ' prev-rank',\n",
    "    'average': ' sg',\n",
    "    'rounds': ' num-rounds',\n",
    "    'measured rounds': ' num-measured'\n",
    "}\n",
    "\n",
    "abbrev_col_names = [ 'name', ' sg' ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "779dfaa6-f14c-4a83-9235-82c2d4a353fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def strokes_gained_per(golf_shot, abbreviate=True):\n",
    "    \n",
    "    if golf_shot.lower() not in strokes_gained_components:\n",
    "        return None\n",
    "    \n",
    "    else:\n",
    "        info = strokes_gained_components.get(golf_shot.lower(), None)\n",
    "        if info is None:\n",
    "            return None\n",
    "        \n",
    "        else:\n",
    "            url = f'https://www.pgatour.com/stats/stat.0{ info[\"url_id\"] }.html'\n",
    "            \n",
    "            ret = pd.read_html(url)[1].reset_index(drop=True)\n",
    "            \n",
    "            ret.columns = ret.columns.str.lower().str.replace('total sg:', ' sg').str.replace('\\xa0', ' ')\n",
    "            \n",
    "            ret = ret.rename(new_col_names, axis=1)\n",
    "            # ret.index = ret['name']\n",
    "            # ret = ret.drop('name', axis=1)\n",
    "            if abbreviate:\n",
    "                ret = ret.loc[:, abbrev_col_names]\n",
    "            \n",
    "            ret.columns = ret.columns.str.replace(' ', f'{strokes_gained_components[golf_shot][\"shortened\"]}-')\n",
    "            \n",
    "            ret.to_pickle(f'../data/pickle-buffer/{strokes_gained_components[golf_shot][\"shortened\"]}-sg.pkl')\n",
    "            \n",
    "            return None\n",
    "        \n",
    "def load_strokes_gained_per(golf_shot):\n",
    "    \n",
    "    #**\n",
    "    strokes_gained_per(golf_shot)\n",
    "    \n",
    "    return pd.read_pickle(f'../data/pickle-buffer/{strokes_gained_components[golf_shot][\"shortened\"]}-sg.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2c837c8f-84de-4731-9389-3b4630d714d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def aggregate_strokes_gained():\n",
    "    \n",
    "    # Create dictionary containing strokes-gained data for each stroke\n",
    "    sg_frames = { golf_shot: load_strokes_gained_per(golf_shot) for golf_shot in strokes_gained_components }\n",
    "\n",
    "    # Initialize frame as tee and merge rest of shots\n",
    "    sgdf = sg_frames['tee']\n",
    "    for k in list(strokes_gained_components.keys())[1:]:\n",
    "        sgdf = sgdf.merge(sg_frames[k])\n",
    "    \n",
    "    ret = (sgdf\n",
    "           .sort_values(by=constants.focus_stat, ascending=False)\n",
    "           .reset_index(drop=True)\n",
    "          )\n",
    "\n",
    "    ret.to_pickle(f'../data/pickle-buffer/strokes-gained.pkl')                                                 \n",
    "                                                 \n",
    "    return None\n",
    "\n",
    "def load_strokes_gained():\n",
    "    \n",
    "    aggregate_strokes_gained()\n",
    "    \n",
    "    return pd.read_pickle('../data/pickle-buffer/strokes-gained.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6b085b7-b0ec-41fa-93b8-05b9fe76fc7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_pga_fanduel():\n",
    "    fd = load_fanduel()\n",
    "    sg = load_strokes_gained()\n",
    "    \n",
    "    focus_stats = [ constants.focus_stat ]\n",
    "    if constants.focus_stat_2 is not None:\n",
    "        focus_stats.append(constants.focus_stat_2)\n",
    "        if constants.focus_stat_3 is not None:\n",
    "            focus_stats.append(constants.focus_stat_3)\n",
    "    \n",
    "    focus_stats = tuple(focus_stats)\n",
    "    \n",
    "    for sg_col in focus_stats:\n",
    "        fd[sg_col] = fd['name'].apply(lambda x: sg.loc[x, sg_col] if x in sg.index else 0.0)\n",
    "        fd[f'{sg_col}-per-10k'] = np.array( 10000 * fd[sg_col] / fd['salary'] )\n",
    "    \n",
    "    #convs = {'name': 'str', 'salary': 'int'}\n",
    "    \n",
    "    #for col in fd.columns:\n",
    "        #fd[col] = fd[col].astype(convs.get(col, 'float'))\n",
    "    \n",
    "    # fd.index = fd['name']\n",
    "    # fd = fd.drop('name', axis=1)\n",
    "                           \n",
    "    fd = (fd\n",
    "          .sort_values(by=[constants.focus_stat], ascending=False)\n",
    "          .dropna()\n",
    "         )\n",
    "    \n",
    "    fd.to_pickle(f'../data/pickle-buffer/{constants.tournament}.pkl')\n",
    "\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e23a9bb-626c-4f39-b68a-3c218c556677",
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "from itertools import combinations\n",
    "\n",
    "from functools import cache\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "#from pandarallel import pandarallel\n",
    "#pandarallel.initialize(use_memory_fs=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b80cdff9-b699-45f3-946a-ca7919b3459d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_constraints():\n",
    "    \n",
    "    combine_pga_fanduel()\n",
    "    ret = pd.read_pickle(f'../data/pickle-buffer/{constants.tournament}.pkl')\n",
    "    \n",
    "    if constraints.min_salary is not None:\n",
    "        \n",
    "        ret = (ret\n",
    "               .loc[ ret['salary']>=constraints.min_salary ]\n",
    "               .reset_index(drop=True)\n",
    "              )\n",
    "    \n",
    "    ret.to_pickle(f'../data/pickle-buffer/optimizer-data.pkl')\n",
    "    \n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54aea71a-b090-4ca5-ac86-df4bc3fdcd97",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_input():\n",
    "    \n",
    "    add_constraints()\n",
    "    ret = pd.read_pickle(f'../data/pickle-buffer/optimizer-data.pkl')\n",
    "    ret_names = ret['name'].values.tolist()\n",
    "    \n",
    "    ret['salary'] /= 100\n",
    "    ret.index = ret['name']\n",
    "    ret = ret.drop('name', axis=1)\n",
    "    \n",
    "    ret.to_pickle(f'../data/pickle-buffer/optimizer-data-clean.pkl')\n",
    "    \n",
    "    return ret_names\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45aa0011-d3be-40af-a9f8-80c702fa4f79",
   "metadata": {},
   "outputs": [],
   "source": [
    "pnames = prepare_input()\n",
    "data = pd.read_pickle(f'../data/pickle-buffer/optimizer-data-clean.pkl')\n",
    "\n",
    "@cache\n",
    "def get_value(name, column):\n",
    "    return( data.loc[name, column] )\n",
    "\n",
    "@cache\n",
    "def sum_values(names, column):\n",
    "    return( sum( [ get_value(name, column) for name in names ] ) )\n",
    "\n",
    "@cache\n",
    "def is_valid_lineup(lineup):\n",
    "    return( sum_values(lineup, 'salary') in constraints.cost_range and len(set(lineup))==6 )\n",
    "\n",
    "@cache\n",
    "def lineup_analysis(lineup):\n",
    "    return(tuple( [ sum_values(tuple(set(lineup)),column) for column in constraints.cols_to_sum ] ) )\n",
    "\n",
    "def lineup_analysis_wrapper(lineup):\n",
    "    return( lineup_analysis(tuple(set(lineup.to_numpy()))) if is_valid_lineup(tuple(set(lineup.to_numpy()))) else (0.0,)*len(constraints.cols_to_sum)  )\n",
    "\n",
    "def create_lineup_2_slices(slate_dict):\n",
    "#     2 things of three\n",
    "    ret_list = list()\n",
    "    \n",
    "    for half_slates in tqdm( [p for p in itertools.product(*slate_dict.values())] ):\n",
    "        \n",
    "        g1,g2,g3 = tuple(sorted(list(half_slates[0])))\n",
    "        g4,g5,g6 = tuple(sorted(list(half_slates[1])))\n",
    "        \n",
    "        lu = (g1,g2,g3,g4,g5,g6)\n",
    "        if is_valid_lineup(lu):\n",
    "            ret_list.append(lu)\n",
    "    \n",
    "    return(tuple(ret_list))\n",
    "\n",
    "def create_lineup_3_slices(slate_dict):\n",
    "    \n",
    "#     3 things of two\n",
    "    return None\n",
    "\n",
    "# Trying to get better about only passing tuples or other completely immutable for default and for cache\n",
    "def create_lineups():\n",
    "    \n",
    "    # Not necessary but makes reading easier\n",
    "    num_players = 6 # (n)\n",
    "    num_slices = constraints.slices\n",
    "    step = int( len(pnames) / num_slices )\n",
    "    \n",
    "    r = int(num_players / num_slices) # (nCr)\n",
    "    \n",
    "\n",
    "    # slates = {f'slate{i+1}': tuple(map( tuple, itertools.combinations(pnames[:int(i*step)], r) )) for i in range(num_slices+1)}\n",
    "    # slates.update( { f'slate{num_slices}': tuple(map( tuple, itertools.combinations(pnames[int(num_slices*step):], r) )) } )\n",
    "    \n",
    "    slates = dict()\n",
    "    \n",
    "    if num_slices == 2:\n",
    "        \n",
    "        slates = {\n",
    "            'slate1': tuple(map( tuple, itertools.combinations(pnames[:step], r) )),\n",
    "            'slate2': tuple(map( tuple, itertools.combinations(pnames[step:], r) ))\n",
    "        }\n",
    "        \n",
    "    elif num_slices == 3:\n",
    "        \n",
    "        slates = {\n",
    "            'slate1': tuple(map( tuple, itertools.combinations(pnames[:step], r) )),\n",
    "            'slate2': tuple(map( tuple, itertools.combinations(pnames[step:int(2*step)], r) )),\n",
    "            'slate3': tuple(map( tuple, itertools.combinations(pnames[int(2*step):], r) )),\n",
    "            \n",
    "        }\n",
    "    \n",
    "    operations = { 2: create_lineup_2_slices(slates), 3: create_lineup_3_slices(slates)}\n",
    "    \n",
    "    lineups = operations[num_slices]\n",
    "    \n",
    "    ret = pd.DataFrame(lineups, columns=['g1','g2','g3','g4','g5','g6'])\n",
    "    #ret[constraints.cols_to_sum] = ret.apply( lineup_analysis_wrapper, axis=1, result_type='expand')\n",
    "    ret[constraints.cols_to_sum] = ret.parallel_apply( lineup_analysis_wrapper, axis=1, result_type='expand' )\n",
    "    \n",
    "    ret['total-sg'] = ret.loc[:, constraints.sg_cols].sum(axis=1)\n",
    "    ret['avg-value'] = ret.loc[:, constraints.val_cols].mean(axis=1)\n",
    "    \n",
    "    ret = (ret\n",
    "           # .sort_values(by=f'{constants.focus_stat}-per-10k', ascending=False)\n",
    "           .sort_values(by='avg-value', ascending=False)\n",
    "           .drop_duplicates()\n",
    "           .reset_index(drop=True)\n",
    "          )\n",
    "    \n",
    "    \n",
    "    ret.to_pickle(f'../data/lineups-created/{constants.tournament_fname()}.pkl')\n",
    "    \n",
    "    print('Done...')\n",
    "    \n",
    "    return None\n",
    "\n",
    "def output_lineups(top_num=100):\n",
    "    return pd.read_pickle(f'../data/lineups-created/{constants.tournament_fname()}.pkl').head(top_num)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ca102ee-44c6-451b-9045-9288d65fa282",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_func():\n",
    "    if constants.create:\n",
    "        create_lineups()\n",
    "    return output_lineups()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8d7923b-7cc5-4e68-b61c-068baa6ad623",
   "metadata": {},
   "outputs": [],
   "source": [
    "create_func()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5168762b-175d-4dc7-afb6-a01d8969e553",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
