{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fb5cf0c2-1fd3-4079-825e-013dd0067d43",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a29a4610-9840-40ba-804e-4549b9fd1f36",
   "metadata": {},
   "source": [
    "**Local:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "72f677fb-6813-4755-a897-704958068b77",
   "metadata": {},
   "outputs": [],
   "source": [
    "import constants\n",
    "import constraints\n",
    "\n",
    "from datagolf import datagolf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b15191a0-2600-44ab-8422-57d6ac1da438",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "svmem(total=67418968064, available=62502248448, percent=7.3, used=4132974592, free=59629232128, active=1323692032, inactive=4686778368, buffers=281501696, cached=3375259648, shared=40611840, slab=1299488768)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import psutil\n",
    "\n",
    "psutil.virtual_memory()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfddc7c5-ab55-4d20-8005-19a42bb3026b",
   "metadata": {},
   "source": [
    "**Optimizer: (bottom)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c795bdd0-8eb7-4840-83a1-0eb3c1007929",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: Pandarallel will run on 16 workers.\n",
      "INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.\n",
      "/dev/shm is 40B   =   4e-08KiB     \n"
     ]
    }
   ],
   "source": [
    "import itertools\n",
    "from itertools import combinations\n",
    "\n",
    "from functools import cache\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from pandarallel import pandarallel\n",
    "pandarallel.initialize(use_memory_fs=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "517ec99c-5e0c-4851-ab67-1b5dcd789e35",
   "metadata": {},
   "outputs": [],
   "source": [
    "constants.pandas_settings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "86bc5c91-4717-4eb7-9758-b8239bcfdf19",
   "metadata": {},
   "outputs": [],
   "source": [
    "def edit_fanduel():\n",
    "    df = pd.read_csv(f'../data/contest-files/{constants.tournament}.csv', usecols=constants.keep_cols)\n",
    "    df.columns = df.columns.str.lower()\n",
    "\n",
    "    ret = (df\n",
    "           .rename({'nickname': 'name'}, axis=1)\n",
    "           #.loc[(df['injury indicator']!='O') & (df['salary']>7000)]\n",
    "           .drop('injury indicator', axis=1)\n",
    "           .dropna()\n",
    "           .reset_index(drop=True)\n",
    "          )\n",
    "\n",
    "    col_types = { 'name': 'str', 'fppg': 'float' }\n",
    "    \n",
    "    for col in ret.columns:\n",
    "        ret[col] = ret[col].astype(col_types.get(col,'int'))\n",
    "    \n",
    "    ret.to_pickle('../data/pickle-buffer/fanduel-data.pkl')\n",
    "    \n",
    "    return None\n",
    "\n",
    "\n",
    "def load_fanduel():\n",
    "    \n",
    "    edit_fanduel()\n",
    "    \n",
    "    return pd.read_pickle('../data/pickle-buffer/fanduel-data.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b7bb2ef2-7946-4f4e-8299-deb1eb487bca",
   "metadata": {},
   "outputs": [],
   "source": [
    "strokes_gained_components = {\n",
    "    'tee': {\n",
    "        'url_id': 2567,\n",
    "        #'url': 'https://www.pgatour.com/stats/stat.02567.html',\n",
    "        'shortened': 'ott'\n",
    "    },\n",
    "    'approach': {\n",
    "        'url_id': 2568,\n",
    "        #'url': 'https://www.pgatour.com/stats/stat.02568.html',\n",
    "        'shortened': 'app'\n",
    "    },\n",
    "    'around': {\n",
    "        'url_id': 2569,\n",
    "        #'url': 'https://www.pgatour.com/stats/stat.02569.html',\n",
    "        'shortened': 'arg'\n",
    "    },\n",
    "    'green': {\n",
    "        'url_id': 2564,\n",
    "        #'url': 'https://www.pgatour.com/stats/stat.02564.html',\n",
    "        'shortened': 'putt'\n",
    "    },\n",
    "    'tee-to-green': {\n",
    "        'url_id': 2674,\n",
    "        #'url': 'https://www.pgatour.com/stats/stat.02674.html',\n",
    "        'shortened' : 'ttg'\n",
    "        }\n",
    "}\n",
    "\n",
    "new_col_names = {\n",
    "    'player name': 'name',\n",
    "    'rank this week': ' cur-rank',\n",
    "    'rank last week': ' prev-rank',\n",
    "    'average': ' sg',\n",
    "    'rounds': ' num-rounds',\n",
    "    'measured rounds': ' num-measured'\n",
    "}\n",
    "\n",
    "abbrev_col_names = [ 'name', ' sg' ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "779dfaa6-f14c-4a83-9235-82c2d4a353fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def strokes_gained_per(golf_shot, abbreviate=True):\n",
    "    \n",
    "    if golf_shot.lower() not in strokes_gained_components:\n",
    "        return None\n",
    "    \n",
    "    else:\n",
    "        info = strokes_gained_components.get(golf_shot.lower(), None)\n",
    "        if info is None:\n",
    "            return None\n",
    "        \n",
    "        else:\n",
    "            url = f'https://www.pgatour.com/stats/stat.0{ info[\"url_id\"] }.html'\n",
    "            \n",
    "            ret = pd.read_html(url)[1].reset_index(drop=True)\n",
    "            \n",
    "            ret.columns = ret.columns.str.lower().str.replace('total sg:', ' sg').str.replace('\\xa0', ' ')\n",
    "            \n",
    "            ret = ret.rename(new_col_names, axis=1)\n",
    "            #ret.index = ret['name']\n",
    "            #ret = ret.drop('name', axis=1)\n",
    "            if abbreviate:\n",
    "                ret = ret.loc[:, abbrev_col_names]\n",
    "            \n",
    "            ret.columns = ret.columns.str.replace(' ', f'{strokes_gained_components[golf_shot][\"shortened\"]}-')\n",
    "            \n",
    "            ret.to_pickle(f'../data/pickle-buffer/{strokes_gained_components[golf_shot][\"shortened\"]}-sg.pkl')\n",
    "            \n",
    "            return None\n",
    "        \n",
    "def load_strokes_gained_per(golf_shot):\n",
    "    \n",
    "    #**\n",
    "    strokes_gained_per(golf_shot)\n",
    "    \n",
    "    return pd.read_pickle(f'../data/pickle-buffer/{strokes_gained_components[golf_shot][\"shortened\"]}-sg.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2c837c8f-84de-4731-9389-3b4630d714d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def aggregate_strokes_gained():\n",
    "    \n",
    "    # Create dictionary containing strokes-gained data for each stroke\n",
    "    sg_frames = { golf_shot: load_strokes_gained_per(golf_shot) for golf_shot in strokes_gained_components }\n",
    "\n",
    "    # Initialize frame as tee and merge rest of shots\n",
    "    sgdf = sg_frames['tee']\n",
    "    for k in list(strokes_gained_components.keys())[1:]:\n",
    "        sgdf = sgdf.merge(sg_frames[k])\n",
    "    \n",
    "    ret = (sgdf\n",
    "           #.sort_values(by=constants.focus_stat, ascending=False)\n",
    "           .reset_index(drop=True)\n",
    "          )\n",
    "\n",
    "    ret.to_pickle(f'../data/pickle-buffer/strokes-gained.pkl')                                                 \n",
    "                                                 \n",
    "    return None\n",
    "\n",
    "def load_strokes_gained():\n",
    "    \n",
    "    aggregate_strokes_gained()\n",
    "    \n",
    "    return pd.read_pickle('../data/pickle-buffer/strokes-gained.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c6b085b7-b0ec-41fa-93b8-05b9fe76fc7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_pga_fanduel():\n",
    "    fd = load_fanduel()\n",
    "    sg = load_strokes_gained()\n",
    "    \n",
    "    focus_stats = [ constants.focus_stat ]\n",
    "    if constants.focus_stat_2 is not None:\n",
    "        focus_stats.append(constants.focus_stat_2)\n",
    "        if constants.focus_stat_3 is not None:\n",
    "            focus_stats.append(constants.focus_stat_3)\n",
    "    \n",
    "    focus_stats = tuple(focus_stats)\n",
    "    \n",
    "    sg_lookup = load_strokes_gained()\n",
    "    sg_lookup.index = sg_lookup['name']\n",
    "    sg_lookup = sg_lookup.drop('name', axis=1)\n",
    "    \n",
    "    for sg_col in focus_stats:\n",
    "        fd[sg_col] = fd['name'].apply(lambda x: sg_lookup.loc[x, sg_col] if x in sg_lookup.index else 0.0)\n",
    "        fd[f'{sg_col}-per-10k'] = np.array( 10000 * fd[sg_col] / fd['salary'] )\n",
    "    \n",
    "    #for sg_col in focus_stats:\n",
    "        #fd[sg_col] = fd['name'].apply(lambda x: sg.loc[x, sg_col] if x in sg.index else 0.0)\n",
    "        #fd[f'{sg_col}-per-10k'] = np.array( 10000 * fd[sg_col] / fd['salary'] )\n",
    "    \n",
    "    #convs = {'name': 'str', 'salary': 'int'}\n",
    "    \n",
    "    #for col in fd.columns:\n",
    "        #fd[col] = fd[col].astype(convs.get(col, 'float'))\n",
    "    \n",
    "    # fd.index = fd['name']\n",
    "    # fd = fd.drop('name', axis=1)\n",
    "                           \n",
    "    fd = (fd\n",
    "          .sort_values(by=[constants.focus_stat], ascending=False)\n",
    "          .dropna()\n",
    "         )\n",
    "    \n",
    "    fd.to_pickle(f'../data/pickle-buffer/{constants.tournament}.pkl')\n",
    "\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b80cdff9-b699-45f3-946a-ca7919b3459d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_constraints():\n",
    "    \n",
    "    combine_pga_fanduel()\n",
    "    ret = pd.read_pickle(f'../data/pickle-buffer/{constants.tournament}.pkl')\n",
    "    \n",
    "    if constraints.min_salary is not None:\n",
    "        print(f'Excluding players less than ${constraints.min_salary}...')\n",
    "        ret = (ret\n",
    "               .loc[ ret['salary']>=constraints.min_salary ]\n",
    "               .reset_index(drop=True)\n",
    "              )\n",
    "\n",
    "        \n",
    "#    ret = (ret\n",
    "#           .loc[ ret['name'].isin(dapi.players_who_made_cut()) ]\n",
    "#           .reset_index(drop=True)\n",
    "#          )\n",
    "    \n",
    "    ret.to_pickle(f'../data/pickle-buffer/optimizer-data.pkl')\n",
    "    \n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "54aea71a-b090-4ca5-ac86-df4bc3fdcd97",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_input():\n",
    "    \n",
    "    add_constraints()\n",
    "    ret = pd.read_pickle(f'../data/pickle-buffer/optimizer-data.pkl')\n",
    "    ret_names = ret['name'].values.tolist()\n",
    "    \n",
    "    ret['proj-pts'] = ret['name'].apply(datagolf.proj_pts)\n",
    "    #ret['cfit-adj'] = ret['name'].apply(dapi.proj_skd)\n",
    "    \n",
    "    #ret['cfit-pts'] = ret['proj-pts']+(ret['proj-pts']*ret['cfit-adj'])\n",
    "    \n",
    "    ret['salary'] /= 100\n",
    "    ret.index = ret['name']\n",
    "    ret = ret.drop('name', axis=1)\n",
    "    \n",
    "    ret.to_pickle(f'../data/pickle-buffer/optimizer-data-clean.pkl')\n",
    "    \n",
    "    return ret_names\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62f1bcc7-fc63-4a41-987b-4f62d033881c",
   "metadata": {
    "tags": []
   },
   "source": [
    "`from numba import vectorize\n",
    "\n",
    "@vectorize(['float32(float32, float32)'], target='cuda')\n",
    "def Multi(a, b):\n",
    "    return a*b`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "45aa0011-d3be-40af-a9f8-80c702fa4f79",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Excluding players less than $8000...\n"
     ]
    }
   ],
   "source": [
    "pnames = prepare_input()\n",
    "data = pd.read_pickle(f'../data/pickle-buffer/optimizer-data-clean.pkl')\n",
    "\n",
    "@cache\n",
    "def get_value(name, column):\n",
    "    return( data.loc[name, column] )\n",
    "\n",
    "@cache\n",
    "def sum_values(names, column):\n",
    "    return( sum( [ get_value(name, column) for name in names ] ) )\n",
    "\n",
    "@cache\n",
    "def is_valid_lineup(lineup):\n",
    "    return( sum_values(lineup, 'salary') in constraints.cost_range and len(set(lineup))==6 )\n",
    "\n",
    "@cache\n",
    "def lineup_analysis(lineup):\n",
    "    return(tuple( [ sum_values(tuple(set(lineup)),column) for column in constraints.cols_to_sum ] ) )\n",
    "\n",
    "def lineup_analysis_wrapper(lineup):\n",
    "    return( lineup_analysis(tuple(set(lineup.to_numpy()))) if is_valid_lineup(tuple(set(lineup.to_numpy()))) else (0.0,)*len(constraints.cols_to_sum)  )\n",
    "\n",
    "def create_lineup_2_slices(slate_dict):\n",
    "#     2 things of three\n",
    "    ret_list = list()\n",
    "    \n",
    "    for half_slates in tqdm( [p for p in itertools.product(*slate_dict.values())] ):\n",
    "        \n",
    "        g1,g2,g3 = tuple(sorted(list(half_slates[0])))\n",
    "        g4,g5,g6 = tuple(sorted(list(half_slates[1])))\n",
    "        \n",
    "        lu = (g1,g2,g3,g4,g5,g6)\n",
    "        if is_valid_lineup(lu):\n",
    "            ret_list.append(lu)\n",
    "    \n",
    "    return tuple(ret_list)\n",
    "\n",
    "def create_lineup_3_slices(slate_dict):\n",
    "    \n",
    "#     3 things of two\n",
    "    ret_list = list()\n",
    "    \n",
    "    for third_slates in tqdm( [p for p in itertools.product(*slate_dict.values())] ):\n",
    "        \n",
    "        g1,g2 = tuple(sorted(list(third_slates[0])))\n",
    "        g3,g4 = tuple(sorted(list(third_slates[1])))\n",
    "        g5,g6 = tuple(sorted(list(third_slates[2])))\n",
    "        \n",
    "        lu = (g1,g2,g3,g4,g5,g6)\n",
    "        if is_valid_lineup(lu):\n",
    "            ret_list.append(lu)\n",
    "    \n",
    "    return tuple(ret_list)\n",
    "\n",
    "# Trying to get better about only passing tuples or other completely immutable for default and for cache\n",
    "def create_lineups():\n",
    "    \n",
    "    # Not necessary but makes reading easier\n",
    "    num_players = 6 # (n)\n",
    "    num_slices = constraints.slices\n",
    "    \n",
    "    \n",
    "    step = int( len(pnames) * num_slices**-1 ) # Refers to partition of all names --> 2 slices of 120 players == (:120,120:)\n",
    "    r = int(num_players / num_slices) # (nCr)\n",
    "    #     All possible combos for each half of pnames, dont intersect as of rn\n",
    "    \n",
    "    slates = dict()\n",
    "    \n",
    "    if num_slices == 2:\n",
    "        \n",
    "        slates = {\n",
    "            'slate1': tuple(map( tuple, itertools.combinations(pnames[:step], r) )),\n",
    "            'slate2': tuple(map( tuple, itertools.combinations(pnames[step:], r) ))\n",
    "        }\n",
    "        \n",
    "    elif num_slices == 3:\n",
    "\n",
    "        slates = {\n",
    "            'slate1': tuple(map( tuple, itertools.combinations(pnames[:step], r) )),\n",
    "            'slate2': tuple(map( tuple, itertools.combinations(pnames[step:int(2*step)], r) )),\n",
    "            'slate3': tuple(map( tuple, itertools.combinations(pnames[int(2*step):], r) )),\n",
    "            \n",
    "        }\n",
    "    \n",
    "    #operations = { 2: create_lineup_2_slices(slates), 3: create_lineup_3_slices(slates)}\n",
    "    \n",
    "    lineups = create_lineup_2_slices(slates) if num_slices==2 else create_lineup_3_slices(slates)\n",
    "    \n",
    "    ret = pd.DataFrame(lineups, columns=['g1','g2','g3','g4','g5','g6'])\n",
    "    \n",
    "    # Badda bing\n",
    "    ret[constraints.cols_to_sum] = ret.parallel_apply( lineup_analysis_wrapper, axis=1, result_type='expand' )\n",
    "    \n",
    "    ret = (ret\n",
    "           # .sort_values(by=f'{constants.focus_stat}-per-10k', ascending=False)\n",
    "           .sort_values(by='proj-pts', ascending=False)\n",
    "           .drop_duplicates()\n",
    "           .reset_index(drop=True)\n",
    "          )\n",
    "    \n",
    "    \n",
    "    ret.to_pickle(f'../data/lineups-created/{constants.tournament}.pkl')\n",
    "    \n",
    "    print('Done...')\n",
    "    \n",
    "    return None\n",
    "\n",
    "def output_lineups(top_num=100):\n",
    "    return pd.read_pickle(f'../data/lineups-created/{constants.tournament}.pkl').head(top_num)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8e61588f-de3e-436c-b1bc-3c55bee3409f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def output_lineups_by(sort_by=('proj-pts',)):\n",
    "    return pd.read_pickle(f'../data/lineups-created/{constants.tournament}.pkl').sort_values(by=sort_by[0], ascending=False).head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0ca102ee-44c6-451b-9045-9288d65fa282",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_func():\n",
    "    if constants.create:\n",
    "        create_lineups()\n",
    "    #return output_lineups_by()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8d7923b-7cc5-4e68-b61c-068baa6ad623",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0dfc9fdb6a104d36ab8048b47924fe2f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/29250000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "create_func()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9585c470-1042-4b7f-815e-7e3cacf9be2c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
